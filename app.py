import streamlit as st
import pandas as pd
import datetime
import re

import numpy as np
import cv2
from PIL import Image

from google.cloud import vision
from google.oauth2 import service_account
import gspread

# =========================================================
# 0) CONFIG
# =========================================================
KEY_FILE = "credentials.json"             # ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô‡∏£‡∏±‡∏ô local
SHEET_NAME = "Bothong_Meter_Data"
APP_TITLE = "üíß‚ö° ‡∏ö‡πà‡∏≠‡∏ó‡∏≠‡∏á ‡πÄ‡∏£‡∏™‡∏ã‡∏¥‡πÄ‡∏î‡πâ‡∏ô‡∏ó‡πå (Meter OCR Pro)"

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‚Äú‡πÄ‡∏û‡∏î‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á)
DEFAULT_MAX_JUMP_WATER = 200     # ‡∏´‡∏ô‡πà‡∏ß‡∏¢/‡∏£‡∏≠‡∏ö
DEFAULT_MAX_JUMP_ELEC  = 5000    # ‡∏´‡∏ô‡πà‡∏ß‡∏¢/‡∏£‡∏≠‡∏ö

st.set_page_config(page_title="‡∏ö‡πà‡∏≠‡∏ó‡∏≠‡∏á ‡πÄ‡∏£‡∏™‡∏ã‡∏¥‡πÄ‡∏î‡πâ‡∏ô‡∏ó‡πå", page_icon="üìù", layout="centered")


# =========================================================
# 1) CONNECTIONS (Vision + Google Sheet)
# =========================================================
@st.cache_resource
def init_connection():
    try:
        my_scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive",
            "https://www.googleapis.com/auth/cloud-platform",
        ]

        if "gcp_service_account" in st.secrets:
            creds = service_account.Credentials.from_service_account_info(
                st.secrets["gcp_service_account"], scopes=my_scopes
            )
        else:
            creds = service_account.Credentials.from_service_account_file(
                KEY_FILE, scopes=my_scopes
            )

        vision_client = vision.ImageAnnotatorClient(credentials=creds)
        gc = gspread.authorize(creds)
        sh = gc.open(SHEET_NAME)
        return vision_client, sh
    except Exception as e:
        st.error(f"‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return None, None


vision_client, sh = init_connection()


# =========================================================
# 2) IMAGE UTILS (ROI + PREPROCESS + AUTO DETECT)
# =========================================================
def pil_to_cv2(pil_img: Image.Image) -> np.ndarray:
    arr = np.array(pil_img.convert("RGB"))
    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)

def cv2_to_pil(cv_img: np.ndarray) -> Image.Image:
    rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb)

def clamp_bbox(x1, y1, x2, y2, w, h):
    x1 = int(max(0, min(x1, w-1)))
    x2 = int(max(1, min(x2, w)))
    y1 = int(max(0, min(y1, h-1)))
    y2 = int(max(1, min(y2, h)))
    if x2 <= x1: x2 = min(w, x1 + 1)
    if y2 <= y1: y2 = min(h, y1 + 1)
    return x1, y1, x2, y2

def crop_cv(cv_img: np.ndarray, bbox):
    x1, y1, x2, y2 = bbox
    return cv_img[y1:y2, x1:x2].copy()

def preprocess_roi_for_ocr(cv_roi: np.ndarray, meter_type: str) -> np.ndarray:
    """
    ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°/‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå + ‡∏•‡∏î‡πÄ‡∏á‡∏≤/‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢ OCR
    """
    img = cv_roi.copy()

    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô
    img = cv2.resize(img, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ‡∏•‡∏î noise
    gray = cv2.bilateralFilter(gray, 9, 75, 75)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå‡∏î‡πâ‡∏ß‡∏¢ CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)

    # ‡∏ó‡∏≥ threshold
    if meter_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤":
        # ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏°‡∏±‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏î‡∏≥
        th = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            31, 7
        )
    else:
        # ‡∏ô‡πâ‡∏≥‡∏Å‡∏•‡∏°‡∏°‡∏µ‡πÄ‡∏á‡∏≤/‡πÇ‡∏Ñ‡πâ‡∏á ‡πÉ‡∏ä‡πâ threshold ‡∏ó‡∏µ‡πà‡∏ó‡∏ô‡∏Å‡∏ß‡πà‡∏≤
        th = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY,
            41, 10
        )

    # ‡∏õ‡∏£‡∏±‡∏ö morphology ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
    kernel = np.ones((2, 2), np.uint8)
    th = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1)

    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

def find_yellow_label_bbox(cv_img: np.ndarray):
    """
    ‡∏´‡∏≤ bbox ‡∏Ç‡∏≠‡∏á‡∏õ‡πâ‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á (‡πÄ‡∏•‡∏Ç‡∏´‡πâ‡∏≠‡∏á) ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏™‡∏µ
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ bbox (x1,y1,x2,y2) ‡∏´‡∏£‡∏∑‡∏≠ None
    """
    hsv = cv2.cvtColor(cv_img, cv2.COLOR_BGR2HSV)
    # ‡∏ä‡πà‡∏ß‡∏á‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)
    lower = np.array([15, 80, 80])
    upper = np.array([40, 255, 255])
    mask = cv2.inRange(hsv, lower, upper)

    # ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î noise
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return None

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡πâ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î
    cnt = max(contours, key=cv2.contourArea)
    area = cv2.contourArea(cnt)
    if area < 300:  # ‡∏Å‡∏±‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏•‡πá‡∏Å ‡πÜ
        return None

    x, y, w, h = cv2.boundingRect(cnt)
    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
    pad = 8
    H, W = cv_img.shape[:2]
    return clamp_bbox(x-pad, y-pad, x+w+pad, y+h+pad, W, H)

def auto_detect_display_bbox(cv_img: np.ndarray, meter_type: str):
    """
    ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏î‡∏≤ ‚Äú‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‚Äù ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á 100%)
    """
    H, W = cv_img.shape[:2]
    work = cv_img.copy()

    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡πÇ‡∏ã‡∏ô‡∏Å‡∏•‡∏≤‡∏á-‡∏ö‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏•‡πà‡∏≤‡∏á (serial/barcode)
    if meter_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤":
        y_top, y_bot = 0, int(H * 0.75)
    else:
        y_top, y_bot = 0, H  # ‡∏ô‡πâ‡∏≥‡∏Å‡∏•‡∏°‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ
    roi = work[y_top:y_bot, :]

    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)

    edges = cv2.Canny(gray, 60, 180)
    edges = cv2.dilate(edges, np.ones((3, 3), np.uint8), iterations=1)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    best = None
    best_score = -1

    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        area = w * h
        if area < (W * H) * 0.01:
            continue

        ar = w / max(1, h)  # aspect ratio
        # ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏Ç‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏ú‡∏∑‡∏ô‡∏ú‡πâ‡∏≤
        if ar < 1.3 or ar > 6.5:
            continue

        # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô‡∏°‡∏±‡∏Å‡∏î‡∏µ
        cx = x + w / 2
        center_score = 1.0 - abs(cx - (W / 2)) / (W / 2)

        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏ü‡πâ‡∏≤: ‡πÄ‡∏ô‡πâ‡∏ô‡πÇ‡∏ã‡∏ô‡∏ö‡∏ô
        if meter_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤":
            pos_penalty = 1.0 - (y / max(1, (y_bot - y_top)))  # ‡∏¢‡∏¥‡πà‡∏á‡∏ö‡∏ô‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ
        else:
            pos_penalty = 0.7  # ‡∏ô‡πâ‡∏≥‡πÑ‡∏°‡πà strict

        score = (area / (W * H)) * 3.0 + center_score + pos_penalty
        if score > best_score:
            best_score = score
            best = (x, y, x + w, y + h)

    if best is None:
        # fallback: ‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û
        x1 = int(W * 0.20)
        x2 = int(W * 0.80)
        y1 = int(H * 0.35)
        y2 = int(H * 0.60)
        return (x1, y1, x2, y2)

    x1, y1, x2, y2 = best
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å roi coords
    y1 += y_top
    y2 += y_top

    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
    pad_x = int((x2 - x1) * 0.10)
    pad_y = int((y2 - y1) * 0.25)
    return clamp_bbox(x1 - pad_x, y1 - pad_y, x2 + pad_x, y2 + pad_y, W, H)

def encode_cv_to_bytes(cv_img: np.ndarray) -> bytes:
    ok, buf = cv2.imencode(".jpg", cv_img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])
    if not ok:
        raise ValueError("encode image failed")
    return buf.tobytes()


# =========================================================
# 3) OCR (GOOGLE VISION) + PARSING
# =========================================================
def vision_text(image_bytes: bytes) -> str:
    if vision_client is None:
        return ""
    img = vision.Image(content=image_bytes)
    # ‡πÉ‡∏ä‡πâ text_detection (‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤ crop ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡πâ‡∏ß)
    resp = vision_client.text_detection(image=img)
    if resp.text_annotations:
        return resp.text_annotations[0].description
    return ""

def normalize_ocr_text(s: str) -> str:
    # ‡πÅ‡∏Å‡πâ‡∏ï‡∏±‡∏ß‡∏™‡∏•‡∏±‡∏ö‡∏Å‡∏±‡∏ô‡∏ö‡πà‡∏≠‡∏¢
    return (
        s.replace("O", "0").replace("o", "0")
         .replace("I", "1").replace("l", "1").replace("|", "1")
         .replace("S", "5")  # ‡∏ö‡∏≤‡∏á‡∏†‡∏≤‡∏û
    )

def extract_digit_candidates(text: str, meter_type: str):
    """
    ‡∏Ñ‡∏∑‡∏ô list[int] ‡∏Ç‡∏≠‡∏á candidate ‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢)
    """
    t = normalize_ocr_text(text)
    t2 = t.replace(" ", "")  # ‡∏£‡∏ß‡∏°‡∏Å‡∏£‡∏ì‡∏µ "1 4 6 1 3"

    raw = re.findall(r"\d+", t)
    merged = re.findall(r"\d+", t2)
    cands = set(raw + merged)

    nums = []
    for s in cands:
        if len(s) < 3 or len(s) > 6:
            continue
        nums.append(int(s))

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô serial/‡∏õ‡∏µ
    if meter_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤":
        nums = [x for x in nums if 1000 <= x <= 999999]
    else:
        nums = [x for x in nums if 0 <= x <= 999999]
    return sorted(set(nums))

def choose_best_candidate(cands, prev, meter_type: str, max_jump: int):
    """
    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á:
    1) ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÑ‡∏ü 5-6 ‡∏´‡∏•‡∏±‡∏Å, ‡∏ô‡πâ‡∏≥ 4 ‡∏´‡∏•‡∏±‡∏Å)
    2) ‡∏ï‡πâ‡∏≠‡∏á >= prev (‡∏ñ‡πâ‡∏≤ prev ‡∏°‡∏µ)
    3) ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (diff) ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô max_jump (‡∏ñ‡πâ‡∏≤ prev ‡∏°‡∏µ)
    """
    if not cands:
        return 0, []

    scored = []
    for x in cands:
        # length preference
        L = len(str(x))
        if meter_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤":
            len_score = 3 if L == 5 else (2 if L == 6 else 0)
        else:
            len_score = 3 if L == 4 else (1 if L == 3 or L == 5 else 0)

        if prev and x < prev:
            valid = 0
            jump_ok = 0
            diff = prev - x
        else:
            valid = 1
            diff = x - prev if prev else 0
            jump_ok = 1 if (prev == 0 or diff <= max_jump) else 0

        # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: valid + jump_ok + len_score ‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡πÇ‡∏î‡∏î
        score = valid * 5 + jump_ok * 3 + len_score
        # ‡∏ñ‡πâ‡∏≤ prev ‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡∏ä‡∏≠‡∏ö diff ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
        if prev:
            score += max(0, 3 - min(3, diff / max(1, max_jump) * 3))

        scored.append((score, x, diff))

    scored.sort(reverse=True, key=lambda z: (z[0], z[1]))
    best = scored[0][1]
    # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö scored (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå)
    return best, scored


def ocr_room_from_yellow_label(cv_img: np.ndarray) -> str:
    bbox = find_yellow_label_bbox(cv_img)
    if bbox is None:
        return ""
    roi = crop_cv(cv_img, bbox)
    proc = preprocess_roi_for_ocr(roi, meter_type="‡πÑ‡∏ü‡∏ü‡πâ‡∏≤")  # ‡πÉ‡∏ä‡πâ threshold ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏î‡∏≥‡∏ö‡∏ô‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
    txt = vision_text(encode_cv_to_bytes(proc))
    t = normalize_ocr_text(txt)
    # ‡∏´‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô 4 ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô 10 ‡πÄ‡∏ä‡πà‡∏ô 1018, 1020
    m = re.search(r"\b(10\d{2})\b", t.replace(" ", ""))
    if m:
        return m.group(1)
    # fallback 3-4 digits
    m2 = re.search(r"\b(\d{3,4})\b", t.replace(" ", ""))
    return m2.group(1) if m2 else ""


def ocr_meter_from_roi(cv_roi: np.ndarray, meter_type: str, prev: int, max_jump: int):
    proc = preprocess_roi_for_ocr(cv_roi, meter_type=meter_type)
    txt = vision_text(encode_cv_to_bytes(proc))
    cands = extract_digit_candidates(txt, meter_type=meter_type)
    best, scored = choose_best_candidate(cands, prev, meter_type=meter_type, max_jump=max_jump)
    return best, cands, scored, txt, proc


# =========================================================
# 4) SHEET OPS
# =========================================================
def get_last_reading(room, meter_type):
    if sh is None:
        return 0
    try:
        worksheet = sh.worksheet("Latest_Status")
        records = worksheet.get_all_records()
        df = pd.DataFrame(records)
        df["Room"] = df["Room"].astype(str)
        room = str(room)
        row = df[df["Room"] == room]
        if not row.empty:
            col_name = "Last_Water" if meter_type == "‡∏ô‡πâ‡∏≥‡∏õ‡∏£‡∏∞‡∏õ‡∏≤" else "Last_Elec"
            v = row.iloc[0][col_name]
            return int(v) if str(v).strip() != "" else 0
        return 0
    except Exception:
        return 0

def save_data(room, m_type, prev, curr, usage):
    if sh is None:
        return
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_sheet = sh.worksheet("Logs")
    log_sheet.append_row([timestamp, room, m_type, prev, curr, usage])

    status_sheet = sh.worksheet("Latest_Status")
    cell = status_sheet.find(str(room))
    if cell:
        col_index = 2 if m_type == "‡∏ô‡πâ‡∏≥‡∏õ‡∏£‡∏∞‡∏õ‡∏≤" else 3
        status_sheet.update_cell(cell.row, col_index, curr)
    else:
        new_water = curr if m_type == "‡∏ô‡πâ‡∏≥‡∏õ‡∏£‡∏∞‡∏õ‡∏≤" else 0
        new_elec = curr if m_type == "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤" else 0
        status_sheet.append_row([room, new_water, new_elec])


# =========================================================
# 5) UI
# =========================================================
st.title(APP_TITLE)

with st.expander("‚úÖ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ AI ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏°‡πà‡∏ô (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å)"):
    st.markdown(
        """
**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** ‡πÉ‡∏´‡πâ ‚Äú‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‚Äù ‡∏ä‡∏±‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô (Serial/‡∏ö‡∏≤‡∏£‡πå‡πÇ‡∏Ñ‡πâ‡∏î)

1) **‡∏ã‡∏π‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç** ‡πÉ‡∏´‡πâ‡∏Å‡∏¥‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏π‡∏õ ~40‚Äì60%  
2) **‡∏ñ‡∏∑‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏â‡∏≤‡∏Å** (‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≤‡∏¢/‡∏Ç‡∏ß‡∏≤/‡∏ö‡∏ô/‡∏•‡πà‡∏≤‡∏á)  
3) **‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏™‡∏á‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô**: ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÅ‡∏ü‡∏•‡∏ä‡∏ï‡∏£‡∏á ‡πÜ, ‡∏Ç‡∏¢‡∏±‡∏ö‡∏°‡∏∏‡∏°‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏á‡∏≤‡∏Ç‡∏≤‡∏ß‡∏ó‡∏±‡∏ö‡πÄ‡∏•‡∏Ç  
4) **‡πÅ‡∏ï‡∏∞‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç** ‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡πà‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ö‡∏•‡∏≠)  
5) ‡∏ñ‡πâ‡∏≤‡πÅ‡∏™‡∏á‡∏ô‡πâ‡∏≠‡∏¢: ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü/‡πÉ‡∏ä‡πâ‡πÅ‡∏™‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á + ‡πÄ‡∏õ‡∏¥‡∏î HDR  
6) **‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå/‡∏ö‡∏≤‡∏£‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏î‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á** (‡πÄ‡∏û‡∏£‡∏≤‡∏∞ OCR ‡∏à‡∏∞‡πÑ‡∏õ‡∏≠‡πà‡∏≤‡∏ô Serial ‡πÅ‡∏ó‡∏ô)

> ‡∏ó‡∏£‡∏¥‡∏Ñ: ‡∏ñ‡πâ‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏Å‡∏• ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏Ñ‡∏£‡∏≠‡∏õ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ (‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á)
        """
    )

if sh is None:
    st.warning("‚ö†Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö...")
    st.stop()

meter_type = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:", ["‡∏ô‡πâ‡∏≥‡∏õ‡∏£‡∏∞‡∏õ‡∏≤", "‡πÑ‡∏ü‡∏ü‡πâ‡∏≤"], horizontal=True)
max_jump = st.number_input(
    "‡πÄ‡∏û‡∏î‡∏≤‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏ö (‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏¥‡∏î/‡πÄ‡∏•‡∏Ç‡πÇ‡∏î‡∏î)",
    min_value=1,
    value=DEFAULT_MAX_JUMP_WATER if meter_type == "‡∏ô‡πâ‡∏≥‡∏õ‡∏£‡∏∞‡∏õ‡∏≤" else DEFAULT_MAX_JUMP_ELEC,
    step=10,
)

tab1, tab2 = st.tabs(["üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ", "üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ"])
img_file = None

with tab1:
    camera_img = st.camera_input(f"‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå{meter_type}")
    if camera_img:
        img_file = camera_img

with tab2:
    uploaded_img = st.file_uploader(
        f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå{meter_type} ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á", type=["jpg", "png", "jpeg"]
    )
    if uploaded_img:
        img_file = uploaded_img

ai_room = ""
ai_reading = 0
debug = {}

if img_file:
    pil_img = Image.open(img_file).convert("RGB")
    cv_img = pil_to_cv2(pil_img)
    H, W = cv_img.shape[:2]

    st.image(pil_img, caption="‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö", use_container_width=True)

    # --- 5.1 Auto room from yellow label ---
    with st.spinner("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏´‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á..."):
        ai_room = ocr_room_from_yellow_label(cv_img)

    # --- 5.2 Get prev reading if room known (for better candidate selection) ---
    prev_guess = get_last_reading(ai_room, meter_type) if ai_room else 0

    st.subheader("1) ‡∏Ñ‡∏£‡∏≠‡∏õ ‚Äú‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‚Äù (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)")
    st.caption("‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÄ‡∏î‡∏≤‡πÇ‡∏ã‡∏ô‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ ‡πÉ‡∏´‡πâ‡∏Å‡πà‡∏≠‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÑ‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Äú‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‚Äù ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")

    # auto bbox suggestion
    auto_bbox = auto_detect_display_bbox(cv_img, meter_type=meter_type)
    ax1, ay1, ax2, ay2 = auto_bbox

    # sliders (normalize to 0..1 for usability)
    with st.container():
        colA, colB = st.columns(2)
        with colA:
            x1p = st.slider("‡∏ã‡πâ‡∏≤‡∏¢ (x1)", 0.0, 1.0, float(ax1 / W), 0.01)
            x2p = st.slider("‡∏Ç‡∏ß‡∏≤ (x2)", 0.0, 1.0, float(ax2 / W), 0.01)
        with colB:
            y1p = st.slider("‡∏ö‡∏ô (y1)", 0.0, 1.0, float(ay1 / H), 0.01)
            y2p = st.slider("‡∏•‡πà‡∏≤‡∏á (y2)", 0.0, 1.0, float(ay2 / H), 0.01)

    x1 = int(min(x1p, x2p) * W)
    x2 = int(max(x1p, x2p) * W)
    y1 = int(min(y1p, y2p) * H)
    y2 = int(max(y1p, y2p) * H)
    x1, y1, x2, y2 = clamp_bbox(x1, y1, x2, y2, W, H)
    roi_bbox = (x1, y1, x2, y2)

    cv_roi = crop_cv(cv_img, roi_bbox)
    st.image(cv2_to_pil(cv_roi), caption="ROI (‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)", use_container_width=True)

    # OCR ROI
    with st.spinner("ü§ñ OCR ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ROI..."):
        ai_reading, candidates, scored, raw_txt, proc_img = ocr_meter_from_roi(
            cv_roi, meter_type=meter_type, prev=prev_guess, max_jump=max_jump
        )

    st.success("‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")

    # debug expander
    with st.expander("üîç ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î AI (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°/‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç)"):
        st.markdown("**OCR Text (ROI):**")
        st.text(raw_txt)
        st.markdown("**‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô OCR:**")
        st.image(cv2_to_pil(proc_img), use_container_width=True)
        st.markdown("**Candidates:** " + (", ".join(map(str, candidates)) if candidates else "-"))
        if scored:
            st.markdown("**‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î = ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö):**")
            st.write(pd.DataFrame(scored, columns=["score", "value", "diff_vs_prev"]))

# ---------------------------------------------------------
# FORM: CONFIRM + SAVE
# ---------------------------------------------------------
with st.form("meter_form"):
    st.caption("üëá ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")
    c1, c2 = st.columns(2)

    room_number = c1.text_input("‡πÄ‡∏•‡∏Ç‡∏´‡πâ‡∏≠‡∏á (‡∏õ‡πâ‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)", value=ai_room if img_file else "")
    prev = get_last_reading(room_number, meter_type) if room_number else 0
    c1.info(f"‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô: {prev}")

    # ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å candidate ‡πÑ‡∏î‡πâ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if img_file and 'candidates' in locals() and candidates:
        pick_mode = c2.radio("‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏£‡∏≠‡∏Å)", ["‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á"], horizontal=True)
        if pick_mode == "‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥":
            current_reading = c2.number_input("‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå", min_value=0, value=int(ai_reading), step=1)
        elif pick_mode == "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
            chosen = c2.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á", options=candidates, index=candidates.index(ai_reading) if ai_reading in candidates else 0)
            current_reading = int(chosen)
        else:
            current_reading = c2.number_input("‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå", min_value=0, value=0, step=1)
    else:
        current_reading = c2.number_input(
            "‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå",
            min_value=0,
            value=int(ai_reading) if img_file else 0,
            step=1,
            help="‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏Ç‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏°‡∏∏‡∏ô ‡πÉ‡∏´‡πâ‡∏õ‡∏±‡∏î‡πÄ‡∏®‡∏©‡∏•‡∏á (‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤)",
        )

    usage = 0
    if room_number:
        if current_reading >= prev:
            usage = current_reading - prev
        else:
            st.warning("‚ö†Ô∏è ‡πÄ‡∏•‡∏Ç‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô (‡∏≠‡∏≤‡∏à‡∏à‡∏î‡∏ú‡∏¥‡∏î/‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏¥‡∏î)")
            usage = current_reading

        # anomaly check
        if prev and (current_reading - prev) > max_jump:
            st.error(f"‚ùó ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏°‡∏≤‡∏Å‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (>{max_jump}) ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡πá‡∏Ñ ROI/‡∏ñ‡πà‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

        st.metric("‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ", usage)

    submitted = st.form_submit_button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    if submitted:
        if room_number and current_reading > 0:
            save_data(room_number, meter_type, prev, int(current_reading), int(usage))
            st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡πâ‡∏≠‡∏á {room_number} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
            st.balloons()
        else:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö (‡πÄ‡∏•‡∏Ç‡∏´‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏•‡∏Ç‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå)")
